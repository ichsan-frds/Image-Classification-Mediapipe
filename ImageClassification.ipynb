{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "078edfd0",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49c7ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aa7060",
   "metadata": {},
   "source": [
    "## Import Model, Configurations, adn Paths Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "379e6177",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model'\n",
    "image_path = 'data'\n",
    "\n",
    "# List Model & Image Paths\n",
    "model_paths = [os.path.join(model_path, f) for f in os.listdir(model_path) if f.endswith('.tflite')]\n",
    "image_paths = [os.path.join(image_path, f) for f in os.listdir(image_path) if f.lower().endswith(('.JPEG', '.jpeg'))]\n",
    "\n",
    "# Ground Truth yang di-specify Manual\n",
    "true_labels = {\n",
    "    \"ILSVRC2012_val_00000001.JPEG\": \"snake\",\n",
    "    \"ILSVRC2012_val_00000002.JPEG\": \"ski\",\n",
    "    \"ILSVRC2012_val_00000003.JPEG\": \"dog\",\n",
    "    \"ILSVRC2012_val_00000004.JPEG\": \"bowl\",\n",
    "    \"ILSVRC2012_val_00000005.JPEG\": \"bassinet\",\n",
    "    \"ILSVRC2012_val_00000006.JPEG\": \"snake\",\n",
    "    \"ILSVRC2012_val_00000007.JPEG\": \"porcupine\",\n",
    "    \"ILSVRC2012_val_00000008.JPEG\": \"macaron\",\n",
    "    \"ILSVRC2012_val_00000009.JPEG\": \"mouse\",\n",
    "    \"ILSVRC2012_val_00000010.JPEG\": \"dog\",\n",
    "    \"ILSVRC2012_val_00000011.JPEG\": \"coral\",\n",
    "    \"ILSVRC2012_val_00000012.JPEG\": \"cougar\",\n",
    "    \"ILSVRC2012_val_00000013.JPEG\": \"guenon\",\n",
    "    \"ILSVRC2012_val_00000014.JPEG\": \"vehicle\",\n",
    "    \"ILSVRC2012_val_00000015.JPEG\": \"harvester\",\n",
    "    \"ILSVRC2012_val_00000016.JPEG\": \"whale\",\n",
    "    \"ILSVRC2012_val_00000017.JPEG\": \"starfish\",\n",
    "    \"ILSVRC2012_val_00000018.JPEG\": \"vulture\",\n",
    "    \"ILSVRC2012_val_00000019.JPEG\": \"carton\",\n",
    "    \"ILSVRC2012_val_00000020.JPEG\": \"crane\",\n",
    "    \"ILSVRC2012_val_00000021.JPEG\": \"porcupine\",\n",
    "    \"ILSVRC2012_val_00000022.JPEG\": \"hound\",\n",
    "    \"ILSVRC2012_val_00000023.JPEG\": \"granny smith\",\n",
    "    \"ILSVRC2012_val_00000024.JPEG\": \"planetarium\",\n",
    "    \"ILSVRC2012_val_00000025.JPEG\": \"vulture\",\n",
    "    \"ILSVRC2012_val_00000026.JPEG\": \"lamp\",\n",
    "    \"ILSVRC2012_val_00000027.JPEG\": \"wolf\",\n",
    "    \"ILSVRC2012_val_00000028.JPEG\": \"walker hound\",\n",
    "    \"ILSVRC2012_val_00000029.JPEG\": \"snake\",\n",
    "    \"ILSVRC2012_val_00000030.JPEG\": \"roof\",\n",
    "    \"ILSVRC2012_val_00000031.JPEG\": \"butterfly\",\n",
    "    \"ILSVRC2012_val_00000032.JPEG\": \"kart\",\n",
    "    \"ILSVRC2012_val_00000033.JPEG\": \"otter\",\n",
    "    \"ILSVRC2012_val_00000034.JPEG\": \"ballplayer\",\n",
    "    \"ILSVRC2012_val_00000035.JPEG\": \"half track\",\n",
    "    \"ILSVRC2012_val_00000036.JPEG\": \"vestment\",\n",
    "    \"ILSVRC2012_val_00000037.JPEG\": \"common newt\",\n",
    "    \"ILSVRC2012_val_00000038.JPEG\": \"abacus\",\n",
    "    \"ILSVRC2012_val_00000039.JPEG\": \"scabbard\",\n",
    "    \"ILSVRC2012_val_00000040.JPEG\": \"tick\",\n",
    "    \"ILSVRC2012_val_00000041.JPEG\": \"bassinet\",\n",
    "    \"ILSVRC2012_val_00000042.JPEG\": \"barrel\",\n",
    "    \"ILSVRC2012_val_00000043.JPEG\": \"bill\",\n",
    "    \"ILSVRC2012_val_00000044.JPEG\": \"schnauzer\",\n",
    "    \"ILSVRC2012_val_00000045.JPEG\": \"newfoundland\",\n",
    "    \"ILSVRC2012_val_00000046.JPEG\": \"pitcher\",\n",
    "    \"ILSVRC2012_val_00000047.JPEG\": \"freight car\",\n",
    "    \"ILSVRC2012_val_00000048.JPEG\": \"hound\",\n",
    "    \"ILSVRC2012_val_00000049.JPEG\": \"cab\",\n",
    "    \"ILSVRC2012_val_00000050.JPEG\": \"shop\",\n",
    "}\n",
    "\n",
    "model_size = {\n",
    "    \"efficientnet_lite0.tflite\": \"5.3 MB\",\n",
    "    \"efficientnet_lite0_float.tflite\": \"18.1 MB\",\n",
    "    \"efficientnet_lite2.tflite\": \"6.9 MB\",\n",
    "    \"efficientnet_lite2_float.tflite\": \"23.7 MB\"\n",
    "}\n",
    "\n",
    "# Config Model\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "ImageClassifier = mp.tasks.vision.ImageClassifier\n",
    "ImageClassifierOptions = mp.tasks.vision.ImageClassifierOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3822e3",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1bcfc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model efficientnet_lite0.tflite\n",
      "Model Size                  : 5.3 MB\n",
      "Average Latency             : 14.71 ms\n",
      "Top-1 Accuracy              : 84.00%\n",
      "Top-3 Accuracy              : 94.00%\n",
      "Avg Confidence (Matched Top): 0.62\n",
      "\n",
      "Model efficientnet_lite0_float.tflite\n",
      "Model Size                  : 18.1 MB\n",
      "Average Latency             : 23.16 ms\n",
      "Top-1 Accuracy              : 88.00%\n",
      "Top-3 Accuracy              : 94.00%\n",
      "Avg Confidence (Matched Top): 0.66\n",
      "\n",
      "Model efficientnet_lite2.tflite\n",
      "Model Size                  : 6.9 MB\n",
      "Average Latency             : 26.28 ms\n",
      "Top-1 Accuracy              : 80.00%\n",
      "Top-3 Accuracy              : 92.00%\n",
      "Avg Confidence (Matched Top): 0.49\n",
      "\n",
      "Model efficientnet_lite2_float.tflite\n",
      "Model Size                  : 23.7 MB\n",
      "Average Latency             : 48.76 ms\n",
      "Top-1 Accuracy              : 84.00%\n",
      "Top-3 Accuracy              : 94.00%\n",
      "Avg Confidence (Matched Top): 0.52\n"
     ]
    }
   ],
   "source": [
    "for model in model_paths:\n",
    "    print(f\"\\nModel {os.path.basename(model)}\")\n",
    "    # Load Model\n",
    "    options = ImageClassifierOptions(\n",
    "        base_options=BaseOptions(model_asset_path=model),\n",
    "        max_results=3,\n",
    "        running_mode=VisionRunningMode.IMAGE\n",
    "    )\n",
    "\n",
    "    # Variabel menyimpan latensi, top-1 acc, top-3 acc, dan confidence\n",
    "    total_latency = 0\n",
    "    top1_correct = 0\n",
    "    top3_correct = 0\n",
    "    matched_confidences = []\n",
    "\n",
    "    with ImageClassifier.create_from_options(options) as classifier:\n",
    "        for img_path in image_paths:\n",
    "            filename = os.path.basename(img_path)\n",
    "\n",
    "            # Load dan Convert Image\n",
    "            img = cv2.imread(img_path)\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=img_rgb)\n",
    "\n",
    "            # Menghitung Latensi & Melakukan Inference\n",
    "            start_time = time.time()\n",
    "            result = classifier.classify(mp_image)\n",
    "            latency = (time.time() - start_time) * 1000\n",
    "            total_latency += latency\n",
    "\n",
    "            # Membandingkan dengan Ground Truth\n",
    "            true_label = true_labels[filename].lower()\n",
    "            categories = result.classifications[0].categories\n",
    "            topk = [c.category_name.lower() for c in categories]\n",
    "            topk_scores = [c.score for c in categories]\n",
    "\n",
    "            # Top-1\n",
    "            if true_label in topk[0]:\n",
    "                top1_correct += 1\n",
    "                matched_confidences.append(topk_scores[0])  # confidence of Top-1\n",
    "\n",
    "            # Top-3 (Jika tidak match dengan top-1)\n",
    "            else:\n",
    "                for name, score in zip(topk[:3], topk_scores[:3]):\n",
    "                    if true_label in name:\n",
    "                        top3_correct += 1\n",
    "                        matched_confidences.append(score)\n",
    "                        break\n",
    "            # Jika match saat Top-1, hitung match untuk Top-3\n",
    "            if true_label in topk[0]:\n",
    "                top3_correct += 1\n",
    "\n",
    "    # Averaging semua metriks dengan jumlah image (confidence averaging dengan image yang berhasil ditebak)\n",
    "    num_images = len(image_paths)\n",
    "    avg_latency = total_latency / num_images\n",
    "    top1_acc = top1_correct / num_images\n",
    "    top3_acc = top3_correct / num_images\n",
    "    avg_matched_conf = sum(matched_confidences) / len(matched_confidences) if matched_confidences else 0\n",
    "\n",
    "    # Menampilkan Hasil Uji\n",
    "    print(f\"Model Size                  : {model_size[os.path.basename(model)]}\")\n",
    "    print(f\"Average Latency             : {avg_latency:.2f} ms\")\n",
    "    print(f\"Top-1 Accuracy              : {top1_acc:.2%}\")\n",
    "    print(f\"Top-3 Accuracy              : {top3_acc:.2%}\")\n",
    "    print(f\"Avg Confidence (Matched Top): {avg_matched_conf:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer-vision-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
